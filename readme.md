# ChatKit Ã— Ollama (Local AI Chat)

A minimal **ChatKit UI + FastAPI backend** setup that connects to a **local Ollama model**.  
This lets you run a ChatGPT-style interface entirely on your machine â€” no OpenAI API costs.

---

## ğŸ§  Overview

- **Frontend:** Next.js + ChatKit (React)
- **Backend:** FastAPI (Python)
- **Model Runtime:** Ollama (`http://localhost:11434/v1`)
- **Cost:** ğŸ’¸ Free â€” all inference is local

You can later swap the model (e.g., `llama3.1`, `qwen2.5`, etc.) or add cloud fallbacks.

---

ğŸ§© System Architecture

[ ChatKit UI (Next.js) ]
         â”‚
         â–¼
[ FastAPI Backend (/api/chat) ]
         â”‚
         â–¼
[ Model Endpoint (OpenAI-Compatible API) ]


## ğŸ“ Project Structure

